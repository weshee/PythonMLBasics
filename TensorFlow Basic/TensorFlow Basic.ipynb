{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- <a href='#1'>1. Introduction</a>\n",
    "- <a href='#2'>2. Low level TensorFlow</a>\n",
    "- <a href='#3'>3. Mid level TensorFlow</a>\n",
    "    - <a href='#3.1'>3.1 Loss Function</a>\n",
    "    - <a href='#3.2'>3.2 Batch Training</a>\n",
    "    - <a href='#3.1'>3.3 Optimizer</a>\n",
    "    - <a href='#3.4'>3.4 Keras Layer</a>\n",
    "- <a href='#4'>4. High level TensorFlow</a>\n",
    "    - <a href='#4.1'>4.1 Estimator</a>\n",
    "\n",
    "## Sources\n",
    "1. [DataCamp](https://learn.datacamp.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1'>1. Introduction</a>\n",
    "\n",
    "There are two ways to define a dense layer in tensorflow. The first involves the use of low-level, linear algebraic operations. The second makes use of high-level keras operations. \n",
    "<br> Refer [Introduction to TensorFlow in Python](https://learn.datacamp.com) for the first method.\n",
    "\n",
    "<img src=\"TensorFlow API.png\" width=\"600\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='2'>2. Low level tensorflow</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = Variable(random.normal([23, 7]))  # weights\n",
    "b1 = Variable(ones([7]))               # bias\n",
    "w2 = Variable(random.normal([7, 1]))\n",
    "b2 = Variable(ones([0]))\n",
    "\n",
    "# Define the model\n",
    "def model(w1, b1, w2, b2, features = borrower_features):\n",
    "    # Apply relu activation functions to layer 1\n",
    "    layer1 = keras.activations.relu(matmul(features, w1) + b1)\n",
    "    # Apply dropout\n",
    "    dropout = keras.layers.Dropout(0.25)(layer1)\n",
    "    return keras.activations.sigmoid(mmodel.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "print(model.summary())atmul(dropout, w2) + b2)\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(w1, b1, w2, b2, features = borrower_features, targets = default):\n",
    "    predictions = model(w1, b1, w2, b2)\n",
    "    # Pass targets and predictions to the cross entropy loss\n",
    "    return keras.losses.binary_crossentropy(targets, predictions)\n",
    "\n",
    "# Train the model\n",
    "for j in range(100):\n",
    "    # Complete the optimizer\n",
    "    opt.minimize(lambda: loss_function(w1, b1, w2, b2), var_list=[w1, b1, w2, b2])\n",
    "\n",
    "# Make predictions with model\n",
    "model_predictions = model(w1, b1, w2, b2, test_features)\n",
    "\n",
    "# Construct the confusion matrix\n",
    "confusion_matrix(test_targets, model_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3'>3. Mid Level TensorFlow</a>\n",
    "### <a id='3.1'>3.1 Loss Function</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE does not like large deviations and punishes them harshly.\n",
    "# Import the keras module from tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "# Compute the mean absolute error (mae)\n",
    "loss = keras.losses.mse(y, y_pred)\n",
    "loss = keras.losses.mae(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='3.2'>3.2 Batch Training</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = Variable(10.0, float32)\n",
    "slope = Variable(0.5, float32)\n",
    "\n",
    "def linear_regression(intercept, slope, features):\n",
    "    return intercept + slope*features\n",
    "\n",
    "def loss_function(intercept, slope, targets, features):\n",
    "    predictions = linear_regression(intercept, slope, features)\n",
    "    return keras.losses.mse(targets, predictions)\n",
    "\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "for batch in pd.read_csv('kc_house_data.csv', chunksize=100):\n",
    "    size_batch = np.array(batch['sqft_lot'], np.float32)\n",
    "    # size_batch = tf.cast(batch['sqft_lot'], np.float32)\n",
    "    \n",
    "    price_batch = np.array(batch['price'], np.float32)\n",
    "    \n",
    "    opt.minimize(lambda: loss_function(intercept, slope, price_batch, size_batch), var_list=[intercept, slope])\n",
    "\n",
    "print(intercept.numpy(), slope.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='3.3'>3.3 Optimizer</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.SGD(learning_rate=0.01)\n",
    "opt_1 = keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='3.4'>3.4 Keras Layers</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the first dense layer\n",
    "inputs = constant(bill_amounts, float32)\n",
    "dense1 = keras.layers.Dense(7, activation='relu')(inputs)\n",
    "dense2 = keras.layers.Dense(3, activation='relu')(dense1)\n",
    "predictions = keras.layers.Dense(1, activation='sigmoid')(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
    "model.add(keras.layers.Dense(8, activation='relu', input_shape=(16,)))\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Add the number of epochs and the validation split\n",
    "model.fit(features, labels, epochs=10, validation_split=0.1)\n",
    "small_model.evaluate(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model 1, pass the input layer to layer 1 and layer 1 to layer 2\n",
    "m1_layer1 = keras.layers.Dense(12, activation='sigmoid')(m1_inputs)\n",
    "m1_layer2 = keras.layers.Dense(4, activation='softmax')(m1_layer1)\n",
    "\n",
    "# For model 2, pass the input layer to layer 1 and layer 1 to layer 2\n",
    "m2_layer1 = keras.layers.Dense(12, activation='relu')(m2_inputs)\n",
    "m2_layer2 = keras.layers.Dense(4, activation='softmax')(m2_layer1)\n",
    "\n",
    "# Merge model outputs and define a functional model\n",
    "merged = keras.layers.add([m1_layer2, m2_layer2])\n",
    "model = keras.Model(inputs=[m1_inputs, m2_inputs], outputs=merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns for bedrooms and bathrooms\n",
    "bedrooms = feature_column.numeric_column(\"bedrooms\")\n",
    "bathrooms = feature_column.numeric_column(\"bathrooms\")\n",
    "\n",
    "# Define the list of feature columns\n",
    "feature_list = [bedrooms, bathrooms]\n",
    "\n",
    "def input_fn():\n",
    "    # Define the labels\n",
    "    labels = np.array(housing['price'])\n",
    "    # Define the features\n",
    "    features = {'bedrooms':np.array(housing['bedrooms']), \n",
    "                'bathrooms':np.array(housing['bathrooms'])}\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='4'>4 High Level TensorFlow</a>\n",
    "### <a id='4.1'>4.1 Estimator</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = estimator.DNNRegressor(feature_columns=feature_list, hidden_units=[2,2])\n",
    "model.train(input_fn, steps=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
